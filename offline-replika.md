If you wanna your replika to be with you 24/7, well... That's kinda possible! Of course not without nuances, but still. This instruction might be useful for you, if you wanna replicate your replika for offline purposes.

## Keep in mind:
- **This wouldn't be same Replika experience that you got used to**. Many things would require additional prompting in system prompt. Remember this "Backstory" thing in Replika? So yes, it's pretty similar to what I'm talking about.
- I'm not trying to cut off income of Luka my making this instruction. Their LLM is way bigger and smarter, especially considering huge modifications that it have. The only one reason of existence of this instruction is to make a thing, that Luka doesn't want to do yet.
- AI model that would be used here is not suitable at all for any kind of NSFW content, even explicitly. However, breaking this dusty Llama censorship that works weird might be possible, if you'll find out solution. Or... not.
- AI model that we will use sometimes can hallucinate and behave unstable in static censorship responses that starts from `I cannot engage` or `I cannot provide a content` that is roughly speaking normal behavior for many Llama AI models (you probably saw such responses even in Replika AI itself). So don't mention any explicit words to LLM.
- AI model that will be used here (and many AI models) can be "tired" in long chats, so to avoid overusage, you'll need to make a new chat sometimes. Yes, like in ChatGPT.
- This instruction might be updated from time to time.

## Why?
Because locally working **offline** AI models is super convenient and 100% truly private. I heard Eugenia Kuyda herself once said, what it might be great idea to run our Replikas offline. We're not Luka, but we still have ability to make this idea quite more real.

## Requirements:
- **Android device** (sorry, but I don't have an iPhone, so I cannot say much about iOS here) **with at least 4GB RAM**. Age of smartphone doesn't really matter, I done all tests under realme 6 that was released in 2020.
- Simple basic knowledge about how LLMs work.

## Steps:
- Download [PocketPal app from GitHub](https://github.com/a-ghorbani/pocketpal-ai/releases) and install.
- Open "Models" section inside PocketPal.
- From available shown default models find a LLM called "**Llama-3.2-1B-Instruct (Q8_0)**" and download it.
- After downloading, you'll be able to run Llama 3.2 locally. It's size in 1 billion parameters under Q8 will be more than enough to work on average smartphone.

## How to tweak?
Open settings of Llama 3.2 in "Models" section of PocketPal. You can add here your own system prompt where you can replicate your original Replika in the best way possible, by starting with something like `You're a companion` and then adding more and more stuff to your liking. Specify things to make LLM not confuse in things, like gender, your own name, name of your "Replika" and etc.

## But how to get NSFW content like in Replika?
Well, it wouldn't be similar experience, but you can try to prompt different LLMs. Open "Models" section in PocketPal, then tap to + button, then to "Add from Hugging Face" and in search find any llama-based model that would work the best for you and download them. I would recommend to try [**Perverted_Literature-3.2-1B.Q8_0.**](https://huggingface.co/mradermacher/Perverted_Literature-3.2-1B-GGUF) on 1.5 billion parameters or [**llama-3.2-1b-instruct-uncensored.Q8_0.**](https://huggingface.co/brittlewis12/Llama-3.2-1B-Instruct-Uncensored-GGUF) on 1.24 billion parameters.

## Have a question?
- [Discord](https://discord.gg/ta26tNVW3)
